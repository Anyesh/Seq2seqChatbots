\BOOKMARK [1][-]{section.1}{Introduction}{}% 1
\BOOKMARK [1][-]{section.2}{History of Chatbots}{}% 2
\BOOKMARK [2][-]{subsection.2.1}{Modelling Conversations}{section.2}% 3
\BOOKMARK [2][-]{subsection.2.2}{Early Approaches}{section.2}% 4
\BOOKMARK [2][-]{subsection.2.3}{The Encoder-Decoder Model}{section.2}% 5
\BOOKMARK [3][-]{subsubsection.2.3.1}{Recurrent Neural Networks}{subsection.2.3}% 6
\BOOKMARK [3][-]{subsubsection.2.3.2}{The Seq2seq Model}{subsection.2.3}% 7
\BOOKMARK [3][-]{subsubsection.2.3.3}{Decoding and OOV}{subsection.2.3}% 8
\BOOKMARK [1][-]{section.3}{Background}{}% 9
\BOOKMARK [2][-]{subsection.3.1}{Recent Chatbot Architectures and Augmentations}{section.3}% 10
\BOOKMARK [3][-]{subsubsection.3.1.1}{Attention}{subsection.3.1}% 11
\BOOKMARK [3][-]{subsubsection.3.1.2}{Context}{subsection.3.1}% 12
\BOOKMARK [3][-]{subsubsection.3.1.3}{Objective Functions}{subsection.3.1}% 13
\BOOKMARK [3][-]{subsubsection.3.1.4}{Additional Features}{subsection.3.1}% 14
\BOOKMARK [3][-]{subsubsection.3.1.5}{Knowledge Bases, Copying and Information Retrieval}{subsection.3.1}% 15
\BOOKMARK [3][-]{subsubsection.3.1.6}{Task-Oriented Approaches}{subsection.3.1}% 16
\BOOKMARK [3][-]{subsubsection.3.1.7}{Decoding and Beam Search}{subsection.3.1}% 17
\BOOKMARK [3][-]{subsubsection.3.1.8}{Reinforcement Learning}{subsection.3.1}% 18
\BOOKMARK [3][-]{subsubsection.3.1.9}{Pretraining}{subsection.3.1}% 19
\BOOKMARK [3][-]{subsubsection.3.1.10}{Additional Encoder-Decoder Models}{subsection.3.1}% 20
\BOOKMARK [3][-]{subsubsection.3.1.11}{Evaluation Methods}{subsection.3.1}% 21
\BOOKMARK [2][-]{subsection.3.2}{Criticism}{section.3}% 22
\BOOKMARK [3][-]{subsubsection.3.2.1}{Datasets}{subsection.3.2}% 23
\BOOKMARK [3][-]{subsubsection.3.2.2}{Loss Function}{subsection.3.2}% 24
\BOOKMARK [3][-]{subsubsection.3.2.3}{Memory}{subsection.3.2}% 25
\BOOKMARK [3][-]{subsubsection.3.2.4}{Evaluation Metrics}{subsection.3.2}% 26
\BOOKMARK [2][-]{subsection.3.3}{Summary}{section.3}% 27
\BOOKMARK [1][-]{section.4}{Experiments}{}% 28
\BOOKMARK [2][-]{subsection.4.1}{The Tranformer Model}{section.4}% 29
\BOOKMARK [2][-]{subsection.4.2}{Datasets}{section.4}% 30
\BOOKMARK [2][-]{subsection.4.3}{Training Details}{section.4}% 31
\BOOKMARK [1][-]{section.5}{Results}{}% 32
\BOOKMARK [2][-]{subsection.5.1}{Quantitative Analysis}{section.5}% 33
\BOOKMARK [2][-]{subsection.5.2}{Qualitative Analysis}{section.5}% 34
\BOOKMARK [1][-]{section.6}{Future Work}{}% 35
\BOOKMARK [2][-]{subsection.6.1}{Ideas Towards Solving The Loss Function Issue}{section.6}% 36
\BOOKMARK [2][-]{subsection.6.2}{Temporal Conditioning and Memory}{section.6}% 37
\BOOKMARK [2][-]{subsection.6.3}{Additional Ideas}{section.6}% 38
\BOOKMARK [1][-]{section.7}{Conclusion}{}% 39
\BOOKMARK [1][-]{section*.2}{References}{}% 40
