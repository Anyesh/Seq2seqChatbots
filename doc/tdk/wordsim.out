\BOOKMARK [1][-]{section.1}{Introduction}{}% 1
\BOOKMARK [1][-]{section.2}{History of Chatbots}{}% 2
\BOOKMARK [2][-]{subsection.2.1}{Modelling Conversations}{section.2}% 3
\BOOKMARK [2][-]{subsection.2.2}{Early Approaches}{section.2}% 4
\BOOKMARK [2][-]{subsection.2.3}{The Encoder-Decoder Model}{section.2}% 5
\BOOKMARK [3][-]{subsubsection.2.3.1}{Recurrent Neural Networks}{subsection.2.3}% 6
\BOOKMARK [3][-]{subsubsection.2.3.2}{The Seq2seq Model}{subsection.2.3}% 7
\BOOKMARK [3][-]{subsubsection.2.3.3}{Deep Seq2seq Models}{subsection.2.3}% 8
\BOOKMARK [3][-]{subsubsection.2.3.4}{Decoding and Vocabulary}{subsection.2.3}% 9
\BOOKMARK [1][-]{section.3}{Background}{}% 10
\BOOKMARK [2][-]{subsection.3.1}{Recent Chatbot Architectures and Augmentations}{section.3}% 11
\BOOKMARK [3][-]{subsubsection.3.1.1}{Attention}{subsection.3.1}% 12
\BOOKMARK [3][-]{subsubsection.3.1.2}{Context}{subsection.3.1}% 13
\BOOKMARK [3][-]{subsubsection.3.1.3}{Hierarchical Models}{subsection.3.1}% 14
\BOOKMARK [3][-]{subsubsection.3.1.4}{Objective Functions}{subsection.3.1}% 15
\BOOKMARK [3][-]{subsubsection.3.1.5}{Additional Features and Priors}{subsection.3.1}% 16
\BOOKMARK [3][-]{subsubsection.3.1.6}{Pretraining}{subsection.3.1}% 17
\BOOKMARK [3][-]{subsubsection.3.1.7}{Knowledge Bases, Copying and Information Retrieval}{subsection.3.1}% 18
\BOOKMARK [3][-]{subsubsection.3.1.8}{Task-Oriented Approaches}{subsection.3.1}% 19
\BOOKMARK [3][-]{subsubsection.3.1.9}{Reinforcement Learning}{subsection.3.1}% 20
\BOOKMARK [3][-]{subsubsection.3.1.10}{Techniques to Augment Seq2seq Models}{subsection.3.1}% 21
\BOOKMARK [3][-]{subsubsection.3.1.11}{Different Encoder-Decoder Models}{subsection.3.1}% 22
\BOOKMARK [3][-]{subsubsection.3.1.12}{Evaluation Methods}{subsection.3.1}% 23
\BOOKMARK [2][-]{subsection.3.2}{Criticism}{section.3}% 24
\BOOKMARK [3][-]{subsubsection.3.2.1}{Datasets}{subsection.3.2}% 25
\BOOKMARK [3][-]{subsubsection.3.2.2}{The Loss Function}{subsection.3.2}% 26
\BOOKMARK [3][-]{subsubsection.3.2.3}{Memory}{subsection.3.2}% 27
\BOOKMARK [3][-]{subsubsection.3.2.4}{Evaluation Metrics}{subsection.3.2}% 28
\BOOKMARK [2][-]{subsection.3.3}{Summary}{section.3}% 29
\BOOKMARK [1][-]{section.4}{Experiments}{}% 30
\BOOKMARK [2][-]{subsection.4.1}{The Tranformer Model}{section.4}% 31
\BOOKMARK [2][-]{subsection.4.2}{Datasets}{section.4}% 32
\BOOKMARK [2][-]{subsection.4.3}{Training Details}{section.4}% 33
\BOOKMARK [1][-]{section.5}{Results}{}% 34
\BOOKMARK [2][-]{subsection.5.1}{Quantitative Analysis}{section.5}% 35
\BOOKMARK [2][-]{subsection.5.2}{Qualitative Analysis}{section.5}% 36
\BOOKMARK [1][-]{section.6}{Future Work}{}% 37
\BOOKMARK [2][-]{subsection.6.1}{Ideas Towards Solving The Loss Function Issue}{section.6}% 38
\BOOKMARK [2][-]{subsection.6.2}{Temporal Conditioning and Memory}{section.6}% 39
\BOOKMARK [2][-]{subsection.6.3}{Additional Ideas}{section.6}% 40
\BOOKMARK [1][-]{section.7}{Conclusion}{}% 41
\BOOKMARK [1][-]{section*.2}{References}{}% 42
